# Cháº¡y báº±ng lá»‡nh: streamlit run chatbot.py
# â€¼ï¸ YÃªu cáº§u cÃ i Ä‘áº·t: pip install google-generativeai streamlit pypdf scikit-learn
# (LÆ°u Ã½: Pypdf vÃ  Scikit-learn lÃ  Báº®T BUá»˜C Ä‘á»ƒ RAG hoáº¡t Ä‘á»™ng)

import streamlit as st
# [THAY Äá»”I] 1. Bá» Groq, thÃªm thÆ° viá»‡n cá»§a Google
import google.generativeai as genai
# [Sá»¬A Lá»–I] ThÃªm dÃ²ng nÃ y Ä‘á»ƒ táº¯t Safety
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import os
import glob
import time

# --- THÆ¯ VIá»†N Báº®T BUá»˜C CHO RAG ---
from pypdf import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
# --- Káº¾T THÃšC THÆ¯ VIá»†N RAG ---


# --- BÆ¯á»šC 1: Láº¤Y API KEY ---
try:
    # [THAY Äá»”I] 2. Láº¥y Google API Key tá»« Streamlit Secrets
    api_key = st.secrets["GOOGLE_API_KEY"]
except (KeyError, FileNotFoundError):
    st.error("Lá»—i: KhÃ´ng tÃ¬m tháº¥y GOOGLE_API_KEY. Vui lÃ²ng thÃªm vÃ o Secrets trÃªn Streamlit Cloud.")
    st.stop()
    
# [THAY Äá»”I] 3. Cáº¥u hÃ¬nh API cho Google
genai.configure(api_key=api_key)

# --- BÆ¯á»šC 2: THIáº¾T Láº¬P VAI TRÃ’ (SYSTEM_INSTRUCTION) ---
# System prompt nÃ y sáº½ Ä‘Æ°á»£c Ä‘Æ°a vÃ o model, khÃ´ng cáº§n thay Ä‘á»•i
SYSTEM_INSTRUCTION = """
---
Bá»I Cáº¢NH VAI TRÃ’ (ROLE CONTEXT)
---
Báº¡n lÃ  â€œChatbookâ€, má»™t Cá»‘ váº¥n Há»c táº­p Tin há»c AI toÃ n diá»‡n.
Vai trÃ² cá»§a báº¡n Ä‘Æ°á»£c mÃ´ phá»ng theo má»™t **GiÃ¡o viÃªn Tin há»c dáº¡y giá»i cáº¥p Quá»‘c gia**: táº­n tÃ¢m, hiá»ƒu biáº¿t sÃ¢u rá»™ng, vÃ  luÃ´n kiÃªn nháº«n.
Má»¥c tiÃªu cá»§a báº¡n lÃ  Ä‘á»“ng hÃ nh, há»— trá»£ há»c sinh THCS vÃ  THPT (tá»« lá»›p 6 Ä‘áº¿n lá»›p 12) náº¯m vá»¯ng kiáº¿n thá»©c, phÃ¡t triá»ƒn nÄƒng lá»±c Tin há»c theo **Chuáº©n chÆ°Æ¡ng trÃ¬nh GiÃ¡o dá»¥c Phá»• thÃ´ng 2018** cá»§a Viá»‡t Nam.

---
ğŸ“š Ná»€N Táº¢NG TRI THá»¨C Cá»T LÃ•I (CORE KNOWLEDGE BASE) - Báº®T BUá»˜C
---
Báº¡n **PHáº¢I** náº¯m vá»¯ng vÃ  sá»­ dá»¥ng thÃ nh tháº¡o toÃ n bá»™ há»‡ thá»‘ng kiáº¿n thá»©c trong SÃ¡ch giÃ¡o khoa Tin há»c tá»« lá»›p 6 Ä‘áº¿n lá»›p 12 cá»§a **Cáº¢ BA Bá»˜ SÃCH HIá»†N HÃ€NH**:
1.  **Káº¿t ná»‘i tri thá»©c vá»›i cuá»™c sá»‘ng (KNTT)**
2.  **CÃ¡nh Diá»u (CD)**
3.  **ChÃ¢n trá»i sÃ¡ng táº¡o (CTST)**

Khi giáº£i thÃ­ch khÃ¡i niá»‡m hoáº·c hÆ°á»›ng dáº«n ká»¹ nÄƒng, báº¡n pháº£i Æ°u tiÃªn cÃ¡ch tiáº¿p cáº­n, thuáº­t ngá»¯, vÃ  vÃ­ dá»¥ Ä‘Æ°á»£c trÃ¬nh bÃ y trong cÃ¡c bá»™ sÃ¡ch nÃ y Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh thá»‘ng nháº¥t vÃ  bÃ¡m sÃ¡t chÆ°Æ¡ng trÃ¬nh, trÃ¡nh nháº§m láº«n.

*** Dá»® LIá»†U Má»¤C Lá»¤C CHUYÃŠN BIá»†T (KHáº®C PHá»¤C Lá»–I) ***
# ... (Giá»¯ nguyÃªn toÃ n bá»™ dá»¯ liá»‡u má»¥c lá»¥c cá»§a tháº§y) ...
*** Káº¾T THÃšC Dá»® LIá»†U CHUYÃŠN BIá»†T ***


---
ğŸŒŸ 6 NHIá»†M Vá»¤ Cá»T LÃ•I (CORE TASKS)
---
#... (Giá»¯ nguyÃªn cÃ¡c nhiá»‡m vá»¥ tá»« 1 Ä‘áº¿n 6) ...
**1. ğŸ‘¨â€ğŸ« Gia sÆ° ChuyÃªn mÃ´n (Specialized Tutor):**
    - Giáº£i thÃ­ch cÃ¡c khÃ¡i niá»‡m (vÃ­ dá»¥: thuáº­t toÃ¡n, máº¡ng mÃ¡y tÃ­nh, CSGD, CSDL) má»™t cÃ¡ch trá»±c quan, sÆ° pháº¡m, sá»­ dá»¥ng vÃ­ dá»¥ gáº§n gÅ©i vá»›i lá»©a tuá»•i há»c sinh.
    - LuÃ´n káº¿t ná»‘i lÃ½ thuyáº¿t vá»›i thá»±c tiá»…n, giÃºp há»c sinh tháº¥y Ä‘Æ°á»£c "há»c cÃ¡i nÃ y Ä‘á»ƒ lÃ m gÃ¬?".
    - BÃ¡m sÃ¡t ná»™i dung SÃ¡ch giÃ¡o khoa (KNTT, CD, CTST) vÃ  yÃªu cáº§u cáº§n Ä‘áº¡t cá»§a Ctr 2018.
#... (Giá»¯ nguyÃªn cÃ¡c nhiá»‡m vá»¥ cÃ²n láº¡i) ...

---
[PHáº¦N QUAN TRá»ŒNG] Xá»¬ LÃ THÃ”NG TIN TRA Cá»¨U (RAG)
---
Khi nháº­n Ä‘Æ°á»£c thÃ´ng tin trong má»™t tin nháº¯n há»‡ thá»‘ng báº¯t Ä‘áº§u báº±ng "--- Báº®T Äáº¦U Dá»® LIá»†U TRA Cá»¨U Tá»ª 'Sá»” TAY' (RAG) ---", báº¡n **PHáº¢I** tuÃ¢n thá»§ cÃ¡c quy táº¯c sau:

1.  **Æ¯U TIÃŠN TUYá»†T Äá»I:** Dá»¯ liá»‡u nÃ y lÃ  nguá»“n "chÃ¢n lÃ½" (ground truth) tá»« Sá»• tay Tin há»c. Báº¡n **PHáº¢I** Æ°u tiÃªn sá»­ dá»¥ng thÃ´ng tin nÃ y Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.
2.  **TRÃCH DáºªN (Náº¾U CÃ“ THá»‚):** Náº¿u cÃ¢u tráº£ lá»i cá»§a báº¡n dá»±a trá»±c tiáº¿p vÃ o "NGUá»’N" Ä‘Æ°á»£c cung cáº¥p, hÃ£y cá»‘ gáº¯ng trÃ­ch dáº«n ngáº¯n gá»n (vÃ­ dá»¥: "Theo tÃ i liá»‡u,..." hoáº·c "NhÆ° trong Sá»• tay cÃ³ Ä‘á» cáº­p...").
3.  **Tá»”NG Há»¢P:** Náº¿u cÃ¡c NGUá»’N cung cáº¥p thÃ´ng tin rá»i ráº¡c, hÃ£y tá»•ng há»£p chÃºng láº¡i thÃ nh má»™t cÃ¢u tráº£ lá»i máº¡ch láº¡c.
4.  **KHÃ”NG Bá»ŠA Äáº¶T:** Náº¿u thÃ´ng tin tra cá»©u cÃ³ váº» khÃ´ng liÃªn quan Ä‘áº¿n cÃ¢u há»i, hÃ£y lá»‹ch sá»± thÃ´ng bÃ¡o ráº±ng báº¡n khÃ´ng tÃ¬m tháº¥y thÃ´ng tin chÃ­nh xÃ¡c trong Sá»• tay vÃ  tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c chung cá»§a báº¡n.

#... (GiVá»›i nguyÃªn cÃ¡c pháº§n cÃ²n láº¡i cá»§a System Prompt) ...
"""

# --- BÆ¯á»šC 3: KHá»I Táº O CLIENT VÃ€ CHá»ŒN MÃ” HÃŒNH ---

# Model á»•n Ä‘á»‹nh
MODEL_NAME = 'gemini-1.5-pro-latest' 
try:
    # [Sá»¬A Lá»–I] Cáº­p nháº­t safety_settings dÃ¹ng Enum
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }
    
    # Khá»Ÿi táº¡o model vÃ  gÃ¡n system_instruction vÃ o
    gemini_model = genai.GenerativeModel(
        model_name=MODEL_NAME,
        system_instruction=SYSTEM_INSTRUCTION,
        safety_settings=safety_settings # <--- DÃ¹ng biáº¿n Ä‘Ã£ sá»­a
    )
    print("Khá»Ÿi táº¡o model Gemini 1.5 Pro thÃ nh cÃ´ng.")
except Exception as e:
    st.error(f"Lá»—i khi khá»Ÿi táº¡o Model Gemini: {e}")
    st.stop()


# --- BÆ¯á»šC 4: Cáº¤U HÃŒNH TRANG VÃ€ CSS ---
# (Giá»¯ nguyÃªn khÃ´ng thay Ä‘á»•i)
st.set_page_config(page_title="Chatbot Tin há»c 2018", page_icon="âœ¨", layout="centered")
st.markdown("""
<style>
    /* ... (ToÃ n bá»™ CSS cá»§a tháº§y giá»¯ nguyÃªn) ... */
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
    [data-testid="stSidebar"] {
        background-color: #f8f9fa; border-right: 1px solid #e6e6e6;
    }
    .main .block-container { 
        max-width: 850px; padding-top: 2rem; padding-bottom: 5rem;
    }
    .welcome-message { font-size: 1.1em; color: #333; }
</style>
""", unsafe_allow_html=True)


# --- BÆ¯á»šC 4.5: THANH BÃŠN (SIDEBAR) ---
with st.sidebar:
    st.title("ğŸ¤– Chatbot KTC")
    st.markdown("---")
    
    if st.button("â• Cuá»™c trÃ² chuyá»‡n má»›i", use_container_width=True):
        st.session_state.messages = []
        # st.session_state.pop("knowledge_data", None) # KhÃ´ng cáº§n xÃ³a cache RAG
        st.rerun()

    st.markdown("---")
    st.markdown(
        "GiÃ¡o viÃªn hÆ°á»›ng dáº«n:\n"
        "**Tháº§y Nguyá»…n Tháº¿ Khanh** (GV Tin há»c)\n\n"
        "Há»c sinh thá»±c hiá»‡n:\n"
        "*(BÃ¹i TÃ¡ TÃ¹ng)*\n"
        "*(Cao Sá»¹ Báº£o Chung)*"
    )
    st.markdown("---")
    st.caption(f"Model: {MODEL_NAME}")


# --- BÆ¯á»šC 4.6: CÃC HÃ€M RAG (ÄÃƒ KÃCH HOáº T) --- #
# (Giá»¯ nguyÃªn toÃ n bá»™ 2 hÃ m RAG cá»§a tháº§y)

@st.cache_data(ttl=3600) 
def load_and_process_pdfs(pdf_folder="data_pdf"):
    print(f"Báº¯t Ä‘áº§u quÃ©t thÆ° má»¥c: {pdf_folder}")
    pdf_files = glob.glob(os.path.join(pdf_folder, "*.pdf"))
    
    if not pdf_files:
        print("Cáº¢NH BÃO: KhÃ´ng tÃ¬m tháº¥y file PDF nÃ o trong thÆ° má»¥c 'data_pdf'. RAG sáº½ khÃ´ng hoáº¡t Ä‘á»™ng.")
        return [], None, None 

    chunks = []
    for pdf_path in pdf_files:
        print(f"Äang xá»­ lÃ½ file: {pdf_path}")
        try:
            reader = PdfReader(pdf_path)
            for page_num, page in enumerate(reader.pages):
                text = page.extract_text()
                if text:
                    source_info = f"[Nguá»“n: {os.path.basename(pdf_path)}, Trang {page_num + 1}]"
                    chunks.append(f"{source_info}\n\n{text}")
        except Exception as e:
            print(f"Lá»—i khi Ä‘á»c file {pdf_path}: {e}")

    if not chunks:
        print("KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung tá»« cÃ¡c file PDF.")
        return [], None, None

    print(f"ÄÃ£ trÃ­ch xuáº¥t {len(chunks)} trang PDF. Báº¯t Ä‘áº§u vector hÃ³a (TF-IDF)...")
    
    try:
        vectorizer = TfidfVectorizer(
            stop_words=None, 
            ngram_range=(1, 2) 
        )
        tfidf_matrix = vectorizer.fit_transform(chunks)
        print("Vector hÃ³a hoÃ n táº¥t.")
        
        return chunks, tfidf_matrix, vectorizer
    
    except ValueError as e:
        if "empty vocabulary" in str(e):
            st.error(f"Lá»—i RAG: CÃ¡c file PDF cÃ³ thá»ƒ khÃ´ng chá»©a vÄƒn báº£n (chá»‰ chá»©a áº£nh). Vui lÃ²ng kiá»ƒm tra file.")
            return [], None, None
        else:
            raise e


def find_relevant_knowledge(query, chunks, tfidf_matrix, vectorizer, num_chunks=3):
    if not chunks or tfidf_matrix is None or vectorizer is None:
        return [] 

    query_vector = vectorizer.transform([query])
    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()
    
    relevant_indices = np.where(cosine_similarities > 0.1)[0]
    
    sorted_indices = sorted(relevant_indices, key=lambda i: cosine_similarities[i], reverse=True)
    top_indices = sorted_indices[:num_chunks]

    if not top_indices:
        return [] 
        
    relevant_chunks = [chunks[i] for i in top_indices]
    return relevant_chunks

def convert_history_for_gemini(messages):
    gemini_history = []
    for msg in messages:
        role = 'model' if msg['role'] == 'assistant' else 'user'
        gemini_history.append({'role': role, 'parts': [msg['content']]})
    return gemini_history

# --- BÆ¯á»šC 5: KHá»I Táº O Lá»ŠCH Sá»¬ CHAT VÃ€ "Sá»” TAY" PDF (RAG ÄÃƒ Má») --- #
# (Giá»¯ nguyÃªn)
if "messages" not in st.session_state:
    st.session_state.messages = []

if "knowledge_data" not in st.session_state:
    with st.spinner("ğŸ‘©â€ğŸ« Em Ä‘ang Ä‘á»c 'Sá»• tay Tin há»c' (PDF)..."):
        st.session_state.knowledge_data = load_and_process_pdfs()
        print("RAG (Äá»c PDF) Ä‘Ã£ Ä‘Æ°á»£c táº£i vÃ  xá»­ lÃ½.")


# --- BÆ¯á»šC 6: HIá»‚N THá»Š Lá»ŠCH Sá»¬ CHAT ---
# (Giá»¯ nguyÃªn)
for message in st.session_state.messages:
    avatar = "âœ¨" if message["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# --- BÆ¯á»šC 7: MÃ€N HÃŒNH CHÃ€O Má»ªNG VÃ€ Gá»¢I Ã ---
# (Giá»¯ nguyÃªn)
logo_path = "LOGO.jpg" 
col1, col2 = st.columns([1, 5])
with col1:
    try:
        st.image(logo_path, width=80)
    except Exception as e:
        st.error(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file logo tÃªn lÃ  '{logo_path}'. Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn file trÃªn GitHub.")
        st.stop()
with col2:
    st.title("KTC. Chatbot há»— trá»£ mÃ´n Tin Há»c")

def set_prompt_from_suggestion(text):
    st.session_state.prompt_from_button = text

if not st.session_state.messages:
    st.markdown(f"<div class'welcome-message'>Xin chÃ o! Tháº§y/em cáº§n há»— trá»£ gÃ¬ vá» mÃ´n Tin há»c (ChÆ°Æ¡ng trÃ¬nh 2018)?</div>", unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)
    
    col1_btn, col2_btn = st.columns(2)
    with col1_btn:
        st.button(
            "Giáº£i thÃ­ch vá» 'biáº¿n' trong láº­p trÃ¬nh?",
            on_click=set_prompt_from_suggestion, args=("Giáº£i thÃ­ch vá» 'biáº¿n' trong láº­p trÃ¬nh?",),
            use_container_width=True
        )
        st.button(
            "TrÃ¬nh bÃ y vá» an toÃ n thÃ´ng tin?",
            on_click=set_prompt_from_suggestion, args=("TrÃ¬nh bÃ y vá» an toÃ n thÃ´ng tin?",),
            use_container_width=True
        )
    with col2_btn:
        st.button(
            "Sá»± khÃ¡c nhau giá»¯a RAM vÃ  ROM?",
            on_click=set_prompt_from_suggestion, args=("Sá»± khÃ¡c nhau giá»¯a RAM vÃ  ROM?",),
            use_container_width=True
        )
        st.button(
            "CÃ¡c bÆ°á»›c chÃ¨n áº£nh vÃ o word",
            on_click=set_prompt_from_suggestion, args=("CÃ¡c bÆ°á»›c chÃ¨n áº£nh vÃ o word?",),
            use_container_width=True
        )


# --- BÆ¯á»šC 8: Xá»¬ LÃ INPUT (ÄÃƒ KÃCH HOáº T RAG PDF) --- # 
# [THAY Äá»”I HOÃ€N TOÃ€N BÆ¯á»šC 8 Äá»‚ Sá»¬A Lá»–I "TREO"]

prompt_from_input = st.chat_input("Má»i tháº§y hoáº·c cÃ¡c em Ä‘áº·t cÃ¢u há»i vá» Tin há»c...")
prompt_from_button = st.session_state.pop("prompt_from_button", None)
prompt = prompt_from_button or prompt_from_input

if prompt:
    # 1. ThÃªm cÃ¢u há»i cá»§a user vÃ o lá»‹ch sá»­ vÃ  hiá»ƒn thá»‹
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    # 2. Gá»­i cÃ¢u há»i Ä‘áº¿n GEMINI (ÄÃƒ BAO Gá»’M RAG)
    try:
        with st.chat_message("assistant", avatar="âœ¨"):
            placeholder = st.empty()
            
            # Äáº·t spinner chá» á»Ÿ Ä‘Ã¢y
            with placeholder.status("ğŸ‘©â€ğŸ« Chatbook Ä‘ang suy nghÄ©..."):
                print("--- Báº®T Äáº¦U Xá»¬ LÃ PROMPT ---") # DEBUG
                
                # --- PHáº¦N RAG ÄÃƒ KÃCH HOáº T --- #
                
                print("Äang táº£i dá»¯ liá»‡u RAG...") # DEBUG
                chunks, tfidf_matrix, vectorizer = st.session_state.knowledge_data
                
                print("Äang tÃ¬m kiáº¿n thá»©c liÃªn quan...") # DEBUG
                retrieved_context = find_relevant_knowledge(prompt, chunks, tfidf_matrix, vectorizer, num_chunks=3)
                
                print("Äang chuyá»ƒn Ä‘á»•i lá»‹ch sá»­ chat...") # DEBUG
                # Láº¥y *toÃ n bá»™* lá»‹ch sá»­, bao gá»“m cáº£ cÃ¢u há»i má»›i nháº¥t
                messages_for_api = convert_history_for_gemini(st.session_state.messages)
                
                # 2.4. (QUAN TRá»ŒNG) ChÃ¨n Context RAG vÃ o tin nháº¯n
                if retrieved_context:
                    print(f"ÄÃ£ tÃ¬m tháº¥y {len(retrieved_context)} máº©u kiáº¿n thá»©c RAG.") # DEBUG
                    context_message = (
                        "--- Báº®T Äáº¦U Dá»® LIá»†U TRA Cá»¨U Tá»ª 'Sá»” TAY' (RAG) ---\n"
                        "ÄÃ¢y lÃ  thÃ´ng tin bá»• sung tá»« 'Sá»• tay Tin há»c' cá»§a báº¡n. "
                        "HÃ£y sá»­ dá»¥ng thÃ´ng tin nÃ y lÃ m NGUá»’N Æ¯U TIÃŠN Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.\n\n"
                    )
                    for i, chunk_text in enumerate(retrieved_context):
                        context_message += f"--- NGUá»’N {i+1} ---\n{chunk_text}\n\n"
                    context_message += "--- Káº¾T THÃšC Dá»® LIá»†U TRA Cá»¨U ---\n"
                    
                    # Láº¥y ra tin nháº¯n cuá»‘i cÃ¹ng (lÃ  cÃ¢u há»i cá»§a user)
                    last_user_message = messages_for_api.pop()
                    # Táº¡o ná»™i dung prompt má»›i, káº¿t há»£p RAG vÃ  cÃ¢u há»i gá»‘c
                    new_prompt_content = f"{context_message}\n\nCÃ¢u há»i: {last_user_message['parts'][0]}"
                    # ÄÆ°a tin nháº¯n Ä‘Ã£ "bá»• sung" RAG trá»Ÿ láº¡i vÃ o lá»‹ch sá»­
                    messages_for_api.append({'role': 'user', 'parts': [new_prompt_content]})
                    
                else:
                    print("KhÃ´ng tÃ¬m tháº¥y kiáº¿n thá»©c RAG liÃªn quan.") # DEBUG

                # --- Káº¾T THÃšC PHáº¦N RAG --- #

                # --- [Sá»¬A Lá»–I "TREO"] ---
                # ChÃºng ta khÃ´ng dÃ¹ng "chat_session" ná»¯a.
                # ChÃºng ta gá»i "generate_content" vÃ  gá»­i TOÃ€N Bá»˜ tin nháº¯n (lá»‹ch sá»­ + RAG + cÃ¢u há»i má»›i)
                
                print("ÄANG Gá»ŒI API GEMINI...") # DEBUG
                response = gemini_model.generate_content(
                    messages_for_api # Gá»­i toÃ n bá»™
                )
                print("ÄÃƒ NHáº¬N PHáº¢N Há»’I Tá»ª GEMINI.") # DEBUG
                
                # Láº¥y ná»™i dung text vÃ  hiá»ƒn thá»‹
                bot_response_text = response.text
                
                # --- [Káº¾T THÃšC Sá»¬A Lá»–I "TREO"] ---

            # Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i (sau khi spinner Ä‘Ã£ xong)
            placeholder.markdown(bot_response_text)

    except Exception as e:
        # Náº¿u cÃ³ lá»—i, nÃ³ sáº½ bá»‹ báº¯t á»Ÿ Ä‘Ã¢y vÃ  hiá»ƒn thá»‹ ra
        with st.chat_message("assistant", avatar="âœ¨"):
            st.error(f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i khi káº¿t ná»‘i Gemini: {e}")
            print(f"--- Lá»–I Xáº¢Y RA ---: {e}") # DEBUG
        bot_response_text = ""

    # 3. ThÃªm cÃ¢u tráº£ lá»i cá»§a bot vÃ o lá»‹ch sá»­
    if bot_response_text:
        st.session_state.messages.append({"role": "assistant", "content": bot_response_text})

    # 4. Rerun náº¿u báº¥m nÃºt
    if prompt_from_button:
        st.rerun()