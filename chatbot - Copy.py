import os
import glob
import base64
import streamlit as st
from pathlib import Path

# --- Imports v·ªõi x·ª≠ l√Ω l·ªói ---
try:
    from pypdf import PdfReader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.documents import Document
    from groq import Groq
    DEPENDENCIES_OK = True
except ImportError as e:
    DEPENDENCIES_OK = False
    IMPORT_ERROR = str(e)

# ==============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG (CONFIG)
# ==============================================================================

st.set_page_config(
    page_title="KTC Chatbot - THCS & THPT Ph·∫°m Ki·ªát",
    page_icon="LOGO.jpg",
    layout="wide",
    initial_sidebar_state="expanded"
)

class AppConfig:
    # Model Config
    LLM_MODEL = 'llama-3.1-8b-instant'
    # Model n√†y h·ªó tr·ª£ ti·∫øng Vi·ªát kh√° t·ªët v√† nh·∫π
    EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    
    # Paths
    PDF_DIR = "PDF_KNOWLEDGE"
    VECTOR_DB_PATH = "faiss_db_index"
    
    # Assets
    LOGO_PROJECT = "LOGO.jpg"
    LOGO_SCHOOL = "LOGO PKS.png"
    
    # RAG Parameters
    CHUNK_SIZE = 1200       # TƒÉng nh·∫π ƒë·ªÉ gi·ªØ ng·ªØ c·∫£nh tr·ªçn v·∫πn h∆°n
    CHUNK_OVERLAP = 250     # Overlap ƒë·ªÉ tr√°nh c·∫Øt gi·ªØa c√¢u
    RETRIEVAL_K = 6         # L·∫•y 6 ƒëo·∫°n vƒÉn b·∫£n li√™n quan nh·∫•t
    RETRIEVAL_TYPE = "mmr"  # D√πng MMR ƒë·ªÉ ƒëa d·∫°ng h√≥a th√¥ng tin t√¨m ki·∫øm

# ==============================================================================
# 2. X·ª¨ L√ù GIAO DI·ªÜN (UI MANAGER) - GI·ªÆ NGUY√äN CSS C·ª¶A TH·∫¶Y
# ==============================================================================

class UIManager:
    @staticmethod
    def get_img_as_base64(file_path):
        if not os.path.exists(file_path):
            return ""
        with open(file_path, "rb") as f:
            data = f.read()
        return base64.b64encode(data).decode()

    @staticmethod
    def inject_custom_css():
        st.markdown("""
        <style>
            /* Import Font hi·ªán ƒë·∫°i 'Inter' */
            @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap');
            
            /* GLOBAL FONT SETTINGS */
            html, body, [class*="css"], .stMarkdown, .stButton, .stTextInput, .stChatInput {
                font-family: 'Inter', sans-serif !important;
            }
            
            /* SIDEBAR STYLING */
            section[data-testid="stSidebar"] {
                background-color: #f8f9fa;
                border-right: 1px solid #e9ecef;
            }
            
            /* Card th√¥ng tin Sidebar */
            .project-card {
                background: white;
                padding: 15px;
                border-radius: 12px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.05);
                margin-bottom: 20px;
                border: 1px solid #dee2e6;
            }
            
            .project-title {
                color: #0077b6;
                font-weight: 800;
                font-size: 1.1rem;
                margin-bottom: 5px;
                text-align: center;
                text-transform: uppercase;
            }
            
            .project-sub {
                font-size: 0.8rem;
                color: #6c757d;
                text-align: center;
                margin-bottom: 15px;
                font-style: italic;
            }

            /* MAIN HEADER */
            .main-header {
                background: linear-gradient(135deg, #023e8a 0%, #0077b6 100%);
                padding: 1.5rem 2rem;
                border-radius: 15px;
                color: white;
                margin-bottom: 2rem;
                box-shadow: 0 8px 20px rgba(0, 119, 182, 0.3);
                display: flex;
                align-items: center;
                justify-content: space-between;
            }
            
            .header-left h1 {
                color: #caf0f8 !important;
                font-weight: 900;
                margin: 0;
                font-size: 2.2rem;
                letter-spacing: -0.5px;
            }
            
            .header-left p {
                color: #e0fbfc;
                margin: 5px 0 0 0;
                font-size: 1rem;
                opacity: 0.9;
            }
            
            .header-right img {
                border-radius: 50%;
                border: 3px solid rgba(255,255,255,0.3);
                box-shadow: 0 4px 10px rgba(0,0,0,0.2);
                width: 100px;
                height: 100px;
                object-fit: cover;
            }

            /* CHAT BUBBLES */
            [data-testid="stChatMessageContent"] {
                border-radius: 15px !important;
                padding: 1rem !important;
                box-shadow: 0 2px 4px rgba(0,0,0,0.05);
            }
            [data-testid="stChatMessageContent"]:has(+ [data-testid="stChatMessageAvatar"]) {
                background: #e3f2fd;
                color: #0d47a1;
            }
            [data-testid="stChatMessageContent"]:not(:has(+ [data-testid="stChatMessageAvatar"])) {
                background: white;
                border: 1px solid #e9ecef;
                border-left: 5px solid #00b4d8;
            }

            /* BUTTONS */
            div.stButton > button {
                border-radius: 8px;
                background-color: white;
                color: #0077b6;
                border: 1px solid #90e0ef;
                transition: all 0.2s;
            }
            div.stButton > button:hover {
                background-color: #0077b6;
                color: white;
                border-color: #0077b6;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            }

            /* ·∫®n footer */
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
        </style>
        """, unsafe_allow_html=True)

    @staticmethod
    def render_sidebar():
        with st.sidebar:
            if os.path.exists(AppConfig.LOGO_SCHOOL):
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    st.image(AppConfig.LOGO_SCHOOL, use_container_width=True)
                st.markdown("<div style='text-align:center; font-weight:700; color:#023e8a; margin-bottom:20px;'>THCS & THPT PH·∫†M KI·ªÜT</div>", unsafe_allow_html=True)
            
            st.markdown("""
            <div class="project-card">
                <div class="project-title">KTC CHATBOT</div>
                <div class="project-sub">S·∫£n ph·∫©m d·ª± thi KHKT c·∫•p tr∆∞·ªùng</div>
                <hr style="margin: 10px 0; border-top: 1px dashed #dee2e6;">
                <div style="font-size: 0.9rem; line-height: 1.6;">
                    <div style="display: flex; justify-content: space-between;">
                        <span style="font-weight: 600; color: #555;">T√°c gi·∫£:</span>
                        <span style="text-align: right; color: #222;"><b>B√πi T√° T√πng</b><br><b>Cao S·ªπ B·∫£o Chung</b></span>
                    </div>
                    <div style="display: flex; justify-content: space-between; margin-top: 8px;">
                        <span style="font-weight: 600; color: #555;">GVHD:</span>
                        <span style="text-align: right; color: #222;">Th·∫ßy <b>Nguy·ªÖn Th·∫ø Khanh</b></span>
                    </div>
                    <div style="display: flex; justify-content: space-between; margin-top: 8px;">
                        <span style="font-weight: 600; color: #555;">NƒÉm h·ªçc:</span>
                        <span style="text-align: right; color: #222;"><b>2025 - 2026</b></span>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("### ‚öôÔ∏è Ti·ªán √≠ch")
            if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠ chat", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
            
            # N√∫t Rebuild DB d√†nh cho Admin/GV khi c·∫≠p nh·∫≠t t√†i li·ªáu
            if st.button("üîÑ C·∫≠p nh·∫≠t d·ªØ li·ªáu m·ªõi", use_container_width=True):
                if os.path.exists(AppConfig.VECTOR_DB_PATH):
                    import shutil
                    shutil.rmtree(AppConfig.VECTOR_DB_PATH)
                st.session_state.pop('vector_db', None)
                st.rerun()

    @staticmethod
    def render_header():
        logo_nhom_b64 = UIManager.get_img_as_base64(AppConfig.LOGO_PROJECT)
        img_html = f'<img src="data:image/jpeg;base64,{logo_nhom_b64}" alt="Logo">' if logo_nhom_b64 else ""

        st.markdown(f"""
        <div class="main-header">
            <div class="header-left">
                <h1>KTC CHATBOT</h1>
                <p style="font-size: 1.1rem; margin-top: 5px;">H·ªçc Tin d·ªÖ d√†ng - Thao t√°c v·ªØng v√†ng</p>
            </div>
            <div class="header-right">
                {img_html}
            </div>
        </div>
        """, unsafe_allow_html=True)

# ==============================================================================
# 3. LOGIC BACKEND (RAG ENGINE)
# ==============================================================================

class RAGEngine:
    @staticmethod
    @st.cache_resource(show_spinner=False)
    def load_groq_client():
        try:
            api_key = st.secrets.get("GROQ_API_KEY") or os.environ.get("GROQ_API_KEY")
            if not api_key: return None
            return Groq(api_key=api_key)
        except: return None

    @staticmethod
    @st.cache_resource(show_spinner=False)
    def load_embedding_model():
        try:
            # S·ª≠ d·ª•ng model h·ªó tr·ª£ ƒëa ng√¥n ng·ªØ t·ªët
            return HuggingFaceEmbeddings(
                model_name=AppConfig.EMBEDDING_MODEL,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
        except Exception as e:
            st.error(f"L·ªói t·∫£i Embedding Model: {e}")
            return None

    @staticmethod
    def build_or_load_vector_db(embeddings):
        if not embeddings: return None

        # 1. Th·ª≠ load t·ª´ ·ªï c·ª©ng tr∆∞·ªõc (Nhanh)
        if os.path.exists(AppConfig.VECTOR_DB_PATH):
            try:
                # print("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ b·ªô nh·ªõ ƒë·ªám...") 
                return FAISS.load_local(AppConfig.VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)
            except Exception as e:
                st.warning(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu c≈©: {e}. ƒêang t·∫°o m·ªõi...")

        # 2. N·∫øu ch∆∞a c√≥ ho·∫∑c l·ªói, t·∫°o m·ªõi t·ª´ PDF (L√¢u h∆°n, ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu)
        if not os.path.exists(AppConfig.PDF_DIR):
            st.error(f"‚ö†Ô∏è Th∆∞ m·ª•c '{AppConfig.PDF_DIR}' kh√¥ng t·ªìn t·∫°i!")
            return None

        pdf_files = glob.glob(os.path.join(AppConfig.PDF_DIR, "*.pdf"))
        # Th√™m h·ªó tr·ª£ file txt n·∫øu c·∫ßn
        txt_files = glob.glob(os.path.join(AppConfig.PDF_DIR, "*.txt"))
        all_files = pdf_files + txt_files
        
        if not all_files:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y t√†i li·ªáu PDF/TXT n√†o!")
            return None

        docs = []
        status_text = st.empty()
        status_text.info(f"üìö ƒêang s·ªë h√≥a {len(all_files)} t√†i li·ªáu. Vui l√≤ng ƒë·ª£i...")

        for file_path in all_files:
            try:
                if file_path.endswith('.pdf'):
                    reader = PdfReader(file_path)
                    for page_num, page in enumerate(reader.pages):
                        text = page.extract_text()
                        if text and len(text.strip()) > 50:
                            # L√†m s·∫°ch c∆° b·∫£n
                            clean_text = text.replace('\x00', '')
                            docs.append(Document(
                                page_content=clean_text, 
                                metadata={"source": os.path.basename(file_path), "page": page_num + 1}
                            ))
                elif file_path.endswith('.txt'):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        text = f.read()
                        if text:
                            docs.append(Document(
                                page_content=text,
                                metadata={"source": os.path.basename(file_path), "page": 1}
                            ))
            except Exception as e:
                print(f"L·ªói ƒë·ªçc file {file_path}: {e}")
                continue

        if docs:
            splitter = RecursiveCharacterTextSplitter(
                chunk_size=AppConfig.CHUNK_SIZE, 
                chunk_overlap=AppConfig.CHUNK_OVERLAP,
                separators=["\n\n", "\n", ".", " ", ""] # ∆Øu ti√™n t√°ch theo ƒëo·∫°n vƒÉn
            )
            splits = splitter.split_documents(docs)
            
            # T·∫°o Vector DB
            vector_db = FAISS.from_documents(splits, embeddings)
            
            # L∆∞u xu·ªëng ·ªï c·ª©ng ƒë·ªÉ l·∫ßn sau d√πng l·∫°i
            vector_db.save_local(AppConfig.VECTOR_DB_PATH)
            
            status_text.empty() # X√≥a th√¥ng b√°o
            return vector_db
        
        status_text.empty()
        return None

    @staticmethod
    def generate_response(client, vector_db, query):
        context_text = ""
        sources = []
        
        if vector_db:
            # C·∫£i ti·∫øn: S·ª≠ d·ª•ng MMR (Maximal Marginal Relevance) ƒë·ªÉ t√¨m ki·∫øm ƒëa d·∫°ng h∆°n
            # fetch_k=20 (t√¨m 20), k=5 (l·∫•y 5 c√°i kh√°c bi·ªát nh·∫•t)
            retriever = vector_db.as_retriever(
                search_type=AppConfig.RETRIEVAL_TYPE, 
                search_kwargs={"k": AppConfig.RETRIEVAL_K, "fetch_k": 20}
            )
            docs = retriever.invoke(query)
            
            for doc in docs:
                src = doc.metadata.get('source', 'T√†i li·ªáu')
                page = doc.metadata.get('page', 'Unknown')
                content = doc.page_content.replace("\n", " ").strip()
                
                # T·∫°o ng·ªØ c·∫£nh c√≥ ƒë·ªãnh danh r√µ r√†ng ƒë·ªÉ LLM tr√≠ch d·∫´n
                context_text += f"""
                ---
                [T√†i li·ªáu: {src}, Trang: {page}]
                N·ªôi dung: {content}
                ---
                """
                sources.append(f"{src} - Trang {page}")

        # Prompt Engineer chuy√™n s√¢u
        system_prompt = f"""B·∫°n l√† KTC Chatbot - Tr·ª£ l√Ω AI gi√°o d·ª•c c·ªßa tr∆∞·ªùng Ph·∫°m Ki·ªát.
        
        NHI·ªÜM V·ª§:
        1. Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a CH√çNH X√ÅC v√†o [NG·ªÆ C·∫¢NH] b√™n d∆∞·ªõi.
        2. N·∫øu th√¥ng tin c√≥ trong ng·ªØ c·∫£nh, h√£y tr√≠ch d·∫´n ngu·ªìn cu·ªëi c√¢u tr·∫£ l·ªùi theo ƒë·ªãnh d·∫°ng [T√™n_File.pdf - Trang X].
        3. N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin trong ng·ªØ c·∫£nh, h√£y n√≥i: "D·ª±a tr√™n t√†i li·ªáu hi·ªán c√≥, m√¨nh ch∆∞a t√¨m th·∫•y th√¥ng tin n√†y." v√† g·ª£i √Ω ki·∫øn th·ª©c chung n·∫øu bi·∫øt (nh∆∞ng ph·∫£i n√≥i r√µ l√† ki·∫øn th·ª©c ngo√†i t√†i li·ªáu).
        4. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch, gi·ªçng vƒÉn th√¢n thi·ªán v·ªõi h·ªçc sinh. H·ªó tr·ª£ t·ªët Python, CSDL, Office.
        
        [NG·ªÆ C·∫¢NH]:
        {context_text}
        """

        try:
            stream = client.chat.completions.create(
                model=AppConfig.LLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": query}
                ],
                stream=True,
                temperature=0.3, # Gi·ªØ m·ª©c s√°ng t·∫°o th·∫•p ƒë·ªÉ b√°m s√°t t√†i li·ªáu
                max_tokens=2000
            )
            # L·ªçc tr√πng l·∫∑p ngu·ªìn
            unique_sources = sorted(list(set(sources)))
            return stream, unique_sources
        except Exception as e:
            return f"L·ªói k·∫øt n·ªëi AI: {str(e)}", []

# ==============================================================================
# 4. MAIN APPLICATION
# ==============================================================================

def main():
    if not DEPENDENCIES_OK:
        st.error(f"‚ö†Ô∏è L·ªói th∆∞ vi·ªán: {IMPORT_ERROR}")
        st.stop()
        
    UIManager.inject_custom_css()
    UIManager.render_sidebar()
    UIManager.render_header()

    # --- KH·ªûI T·∫†O STATE & DATABASE ---
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "üëã Ch√†o b·∫°n! M√¨nh l√† KTC Chatbot. B·∫°n c·∫ßn h·ªó tr·ª£ b√†i t·∫≠p Tin h·ªçc ph·∫ßn n√†o?"}]
    
    # Load Model & DB (Ch·ªâ ch·∫°y 1 l·∫ßn nh·ªù cache)
    groq_client = RAGEngine.load_groq_client()
    
    if "vector_db" not in st.session_state or st.session_state.vector_db is None:
        with st.spinner("üöÄ ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng tri th·ª©c s·ªë..."):
            embeddings = RAGEngine.load_embedding_model()
            st.session_state.vector_db = RAGEngine.build_or_load_vector_db(embeddings)
            if st.session_state.vector_db:
                st.toast("‚úÖ ƒê√£ t·∫£i xong d·ªØ li·ªáu!", icon="üìö")

    # --- HI·ªÇN TH·ªä CHAT ---
    for msg in st.session_state.messages:
        bot_avatar = AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "ü§ñ"
        avatar = "üßë‚Äçüéì" if msg["role"] == "user" else bot_avatar
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    # --- G·ª¢I √ù C√ÇU H·ªéI ---
    if len(st.session_state.messages) < 2:
        st.markdown("##### üí° G·ª£i √Ω √¥n t·∫≠p:")
        cols = st.columns(3)
        prompt_btn = None
        
        if cols[0].button("üêç Python: S·ªë nguy√™n t·ªë"):
            prompt_btn = "Vi·∫øt ch∆∞∆°ng tr√¨nh Python nh·∫≠p v√†o m·ªôt s·ªë nguy√™n n v√† ki·ªÉm tra xem n c√≥ ph·∫£i l√† s·ªë nguy√™n t·ªë hay kh√¥ng. Gi·∫£i th√≠ch code."
        if cols[1].button("üóÉÔ∏è CSDL: Kh√≥a ch√≠nh"):
            prompt_btn = "Gi·∫£i th√≠ch kh√°i ni·ªám Kh√≥a ch√≠nh (Primary Key) trong CSDL quan h·ªá v√† cho v√≠ d·ª• minh h·ªça."
        if cols[2].button("‚öñÔ∏è Lu·∫≠t An ninh m·∫°ng"):
            prompt_btn = "N√™u c√°c h√†nh vi b·ªã nghi√™m c·∫•m theo Lu·∫≠t An ninh m·∫°ng Vi·ªát Nam. Tr√≠ch d·∫´n ƒëi·ªÅu kho·∫£n n·∫øu c√≥."
        
        if prompt_btn:
            st.session_state.temp_input = prompt_btn
            st.rerun()

    # --- X·ª¨ L√ù INPUT ---
    if "temp_input" in st.session_state and st.session_state.temp_input:
        user_input = st.session_state.temp_input
        del st.session_state.temp_input
    else:
        user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n t·∫°i ƒë√¢y...")

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="üßë‚Äçüéì"):
            st.markdown(user_input)

        with st.chat_message("assistant", avatar=AppConfig.LOGO_PROJECT if os.path.exists(AppConfig.LOGO_PROJECT) else "ü§ñ"):
            response_placeholder = st.empty()
            
            if not groq_client:
                st.error("‚ùå Ch∆∞a c·∫•u h√¨nh API Key.")
            else:
                stream, sources = RAGEngine.generate_response(groq_client, st.session_state.vector_db, user_input)
                
                full_response = ""
                if isinstance(stream, str): # Tr∆∞·ªùng h·ª£p l·ªói tr·∫£ v·ªÅ string
                    response_placeholder.error(stream)
                else:
                    for chunk in stream:
                        if chunk.choices[0].delta.content:
                            full_response += chunk.choices[0].delta.content
                            response_placeholder.markdown(full_response + "‚ñå")
                    response_placeholder.markdown(full_response)
                
                # Hi·ªÉn th·ªã ngu·ªìn tham kh·∫£o ƒë·∫πp h∆°n
                if sources:
                    with st.expander("üìö T√†i li·ªáu tham kh·∫£o (ƒê√£ ki·ªÉm ch·ª©ng)"):
                        for src in sources:
                            st.markdown(f"- üìñ *{src}*")
                
                st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()